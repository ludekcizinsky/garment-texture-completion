{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/cizinsky/garment-texture-completion')\n",
    "CKPT_ROOT = '/scratch/izar/cizinsky/garment-completion/models/checkpoints'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from omegaconf import open_dict\n",
    "\n",
    "import torch\n",
    "from helpers.pl_module import GarmentInpainterModule\n",
    "from helpers.dataset import get_dataloaders\n",
    "from helpers.data_utils import denormalise_image_torch\n",
    "from helpers.data_utils import torch_image_to_pil, denormalise_image_torch\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking when I last created the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!stat /scratch/izar/cizinsky/garment-completion/datasets/pbr_maps/dresscode/Batiste_Beige_Argyle/texture_diffuse.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection of trained models\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /scratch/izar/cizinsky/garment-completion/models/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"valiant-resonance-120\"\n",
    "checkpoint_path = f\"{CKPT_ROOT}/{run_name}/last.ckpt\"\n",
    "os.path.exists(checkpoint_path)\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Checkpoint found at {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = checkpoint[\"hyper_parameters\"]\n",
    "\n",
    "cfg.data.num_workers = 10\n",
    "cfg.data.batch_size = 10\n",
    "cfg.data.val_debug_size = 10\n",
    "with open_dict(cfg):\n",
    "    cfg.data.load_all_pbr_maps = True\n",
    "trn_dataloader, val_dataloader = get_dataloaders(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GarmentInpainterModule(cfg, trn_dataloader)\n",
    "model.setup()\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval().cuda()\n",
    "print(\"✅ Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict diffuse, normal, roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.full_pbr_inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, logger=False, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model._load_normal_roughness_decoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "outputs = trainer.predict(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = outputs[0]\n",
    "\n",
    "vae_diffuse = model.model.vae_diffuse\n",
    "vae_normal = model.model.vae_normal.to(dtype=torch.float32)\n",
    "vae_roughness = model.model.vae_roughness.to(dtype=torch.float32)\n",
    "\n",
    "# Decode and save diffuse texture\n",
    "bsz = latents.shape[0]\n",
    "pt_diffuse = vae_diffuse.decode(latents / vae_diffuse.config.scaling_factor, return_dict=False)\n",
    "diffuse = model.inference_pipe.image_processor.postprocess(pt_diffuse[0], output_type=\"pil\", do_denormalize=[True]*bsz)\n",
    "\n",
    "# Decode and save normal map\n",
    "pt_normal = vae_normal.decode(latents / vae_normal.config.scaling_factor, return_dict=False)\n",
    "normal = model.inference_pipe.image_processor.postprocess(pt_normal[0], output_type=\"pil\", do_denormalize=[True]*bsz)\n",
    "\n",
    "# Decode and save roughness map\n",
    "pt_roughness = vae_roughness.decode(latents / vae_roughness.config.scaling_factor, return_dict=False)\n",
    "roughness = model.inference_pipe.image_processor.postprocess(pt_roughness[0], output_type=\"pil\", do_denormalize=[True]*bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(diffuse[0])\n",
    "axs[1].imshow(normal[0])\n",
    "axs[2].imshow(roughness[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "summary_metrics = {}\n",
    "\n",
    "for texture_name in [\"diffuse\", \"normal\", \"roughness\"]:\n",
    "\n",
    "    all_ssim = torch.cat([output[f\"{texture_name}_metrics\"][\"ssim\"] for output in outputs])\n",
    "    all_psnr = torch.cat([output[f\"{texture_name}_metrics\"][\"psnr\"] for output in outputs])\n",
    "    all_lpips = torch.cat([output[f\"{texture_name}_metrics\"][\"lpips\"] for output in outputs])\n",
    "\n",
    "    mean_ssim = all_ssim.mean()\n",
    "    mean_psnr = all_psnr.mean()\n",
    "    mean_lpips = all_lpips.mean()\n",
    "\n",
    "    summary_metrics[f\"{texture_name}_ssim\"] = mean_ssim\n",
    "    summary_metrics[f\"{texture_name}_psnr\"] = mean_psnr\n",
    "    summary_metrics[f\"{texture_name}_lpips\"] = mean_lpips\n",
    "\n",
    "for key, value in summary_metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore role of inference hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = val_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_img = batch[\"partial_diffuse_img\"][2].unsqueeze(0).to(\"cuda\")\n",
    "image_guidance_scale = [2.5, 5.0, 7.5, 10.0]\n",
    "text_guidance_scale = [2.5, 5.0, 7.5, 10.0]\n",
    "results = []\n",
    "for img_scale in image_guidance_scale:\n",
    "    row_results = []\n",
    "    for t_scale in text_guidance_scale:\n",
    "        reconstructed_imgs = model.inference(partial_img, num_inference_steps=50, guidance_scale=t_scale, image_guidance_scale=img_scale)\n",
    "        row_results.extend(reconstructed_imgs)\n",
    "    results.append(row_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    len(image_guidance_scale),\n",
    "    len(text_guidance_scale),\n",
    "    figsize=(5, 5),\n",
    "    tight_layout=True\n",
    ")\n",
    "\n",
    "for i, img_scale in enumerate(image_guidance_scale):\n",
    "    for j, t_scale in enumerate(text_guidance_scale):\n",
    "        ax = axs[i, j]\n",
    "        ax.imshow(results[i][j])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('white')\n",
    "\n",
    "        # keep your per-row / per-col numeric labels if you want\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"{img_scale}\", rotation=0, labelpad=10, va='center')\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"{t_scale}\")\n",
    "\n",
    "# now add the “global” labels\n",
    "fig.supxlabel(\"Text guidance scale\", fontsize=12)\n",
    "fig.supylabel(\"Image guidance scale\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play around with inference hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = val_batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_imgs = model.inference(batch[\"partial_diffuse_img\"][:n].to(\"cuda\"), num_inference_steps=50, guidance_scale=7.5, image_guidance_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_images = [torch_image_to_pil(img) for img in denormalise_image_torch(batch[\"partial_diffuse_img\"][:n])]\n",
    "target_images = [torch_image_to_pil(img) for img in denormalise_image_torch(batch[\"full_diffuse_img\"][:n])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(index):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    axs[0].imshow(cond_images[2])\n",
    "    axs[0].set_title(\"Condition\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(results[index])\n",
    "    img_guidance = image_guidance_scale[index]\n",
    "    axs[1].set_title(f\"Predicted, IMG_GUIDE={img_guidance}\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(target_images[2])\n",
    "    axs[2].set_title(\"Target\")\n",
    "    axs[2].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_images, index=IntSlider(min=0, max=len(results)-1, step=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect results of the ablation on image vs text guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = \"/scratch/izar/cizinsky/garment-completion/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init()\n",
    "artifact = run.use_artifact('ludekcizinsky/pbr-generation/run-w5daifhx-best_inference_setup:v0', type='run_table')\n",
    "artifact.download(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{tmp_dir}/best_inference_setup.table.json', 'r') as f:\n",
    "    table_json = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    table_json['data'],\n",
    "    columns=table_json['columns']\n",
    ")\n",
    "\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"lpips\"  # or \"psnr\", or \"lpips\"\n",
    "\n",
    "# determine sort order & arrow\n",
    "ascending = (metric == \"lpips\")\n",
    "arrow = \"↓\" if metric == \"lpips\" else \"↑\"\n",
    "\n",
    "# ─── 2. AGGREGATE MEAN METRIC ───────────────────────────────────────────────────\n",
    "grouped = (\n",
    "    df\n",
    "    .groupby(['text_scale','img_scale'])\n",
    "    .agg(mean_val=(metric, 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ─── 3. MAKE A COMBO LABEL ──────────────────────────────────────────────────────\n",
    "grouped['combo'] = grouped.apply(\n",
    "    lambda r: f\"({r.text_scale}, {r.img_scale})\", axis=1\n",
    ")\n",
    "\n",
    "# ─── 4. SORT & FLAG TOP-3 ───────────────────────────────────────────────────────\n",
    "grouped = grouped.sort_values('mean_val', ascending=ascending).reset_index(drop=True)\n",
    "grouped['highlight'] = ['Top 3' if i < 3 else 'Other' for i in range(len(grouped))]\n",
    "\n",
    "# ─── 5. PLOT ───────────────────────────────────────────────────────────────────\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "bar = sns.barplot(\n",
    "    data=grouped,\n",
    "    x='combo', y='mean_val',\n",
    "    hue='highlight', dodge=False,\n",
    "    palette={'Top 3': \"#08023d\", 'Other': 'lightgrey'}\n",
    ")\n",
    "\n",
    "# fix tick positions & labels\n",
    "ax = bar\n",
    "ax.set_xticks(range(len(grouped)))\n",
    "ax.set_xticklabels(grouped['combo'], rotation=45, ha='right')\n",
    "\n",
    "# clean up spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# labels & title\n",
    "bar.set_xlabel('Guidance (Text scale, Img scale)')\n",
    "bar.set_ylabel(f\"Mean {metric.upper()}\")\n",
    "bar.set_title(f\"Mean (over 100 samples) {metric.upper()} ({arrow}) per guidance configuration\")\n",
    "\n",
    "# legend\n",
    "bar.legend_.set_title(None)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    df\n",
    "    .groupby(['text_scale','img_scale'])\n",
    "    .agg(mean_ssim = ('ssim','mean'),\n",
    "         mean_psnr = ('psnr','mean'),\n",
    "         mean_lpips= ('lpips','mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Copy to avoid modifying original\n",
    "ranking_df = grouped.copy()\n",
    "\n",
    "# Compute ranks — higher is better for SSIM and PSNR, lower is better for LPIPS\n",
    "ranking_df['rank_ssim'] = ranking_df['mean_ssim'].rank(ascending=False)\n",
    "ranking_df['rank_psnr'] = ranking_df['mean_psnr'].rank(ascending=False)\n",
    "ranking_df['rank_lpips'] = ranking_df['mean_lpips'].rank(ascending=True)\n",
    "\n",
    "# Compute average rank\n",
    "ranking_df['mean_rank'] = ranking_df[['rank_ssim', 'rank_psnr', 'rank_lpips']].mean(axis=1)\n",
    "\n",
    "# Optional: add label column for clarity\n",
    "ranking_df['combo'] = ranking_df.apply(lambda r: f\"({r.text_scale}, {r.img_scale})\", axis=1)\n",
    "\n",
    "# Sort by mean rank\n",
    "ranking_df = ranking_df.sort_values('mean_rank')\n",
    "\n",
    "# Select summary columns\n",
    "summary = ranking_df[['combo', 'rank_ssim', 'rank_psnr', 'rank_lpips', 'mean_rank']]\n",
    "\n",
    "summary.iloc[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
