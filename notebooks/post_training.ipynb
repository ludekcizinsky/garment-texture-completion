{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/cizinsky/garment-texture-completion')\n",
    "CKPT_ROOT = '/scratch/izar/cizinsky/garment-completion/checkpoints'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "\n",
    "from helpers.pl_module import GarmentInpainterModule\n",
    "from helpers.dataset import get_dataloaders\n",
    "from helpers.data_utils import denormalise_image_torch\n",
    "from helpers.data_utils import torch_image_to_pil, denormalise_image_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection of trained models\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lilac-hill-102\n"
     ]
    }
   ],
   "source": [
    "!ls /scratch/izar/cizinsky/garment-completion/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = \"lilac-hill-102\"\n",
    "checkpoint_path = f\"{CKPT_ROOT}/{run_name}/last.ckpt\"\n",
    "os.path.exists(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cizinsky/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 10, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
    "cfg = checkpoint[\"hyper_parameters\"]\n",
    "trn_dataloader, val_dataloader = get_dataloaders(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded!\n"
     ]
    }
   ],
   "source": [
    "model = GarmentInpainterModule(cfg, trn_dataloader).to(torch.float16)\n",
    "model.setup()\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval().cuda()\n",
    "print(\"✅ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Denoising loop during inference: 100%|██████████| 50/50 [00:39<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "reconstructed_imgs = model.inference(batch[\"partial_diffuse_img\"].to(\"cuda\"), strength=1.0, num_inference_steps=50, guidance_scale=5.0)\n",
    "cond_images = [torch_image_to_pil(img) for img in denormalise_image_torch(batch[\"partial_diffuse_img\"])]\n",
    "pred_images = [torch_image_to_pil(img) for img in denormalise_image_torch(reconstructed_imgs)]\n",
    "target_images = [torch_image_to_pil(img) for img in denormalise_image_torch(batch[\"full_diffuse_img\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09367f326f5442fd8726ebf6ebdb6bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=19), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_images(index):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    axs[0].imshow(cond_images[index])\n",
    "    axs[0].set_title(\"Condition\")\n",
    "    axs[0].axis(\"off\")\n",
    "    axs[1].imshow(pred_images[index])\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[2].imshow(target_images[index])\n",
    "    axs[2].set_title(\"Target\")\n",
    "    axs[2].axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_images, index=IntSlider(min=0, max=len(pred_images)-1, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
